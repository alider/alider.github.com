<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>JavaDetails by alider</title>

    <link rel="stylesheet" href="/stylesheets/styles.css">
    <link rel="stylesheet" href="/stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>JavaDetails</h1>
        <p></p>
        <p class="view"><a href="https://github.com/alider">View My GitHub Profile</a></p>
        <h4>Topics:</h4>
        <ul class="posts">
          
            <li><small><span>01 May 2012</span></small> <span><a href="/2012/05/01/circuit-breaker-pattern-revisited.html">Circuit Breaker Pattern Revisited</a></span></li>
          
            <li><small><span>21 Mar 2012</span></small> <span><a href="/2012/03/21/java-array-memory-allocation.html">Java array memory allocation</a></span></li>
          
            <li><small><span>12 Feb 2012</span></small> <span><a href="/2012/02/12/the-best-abstractions-are-your-own.html">The best abstractions are your own</a></span></li>
          
            <li><small><span>05 Jan 2012</span></small> <span><a href="/2012/01/05/how-fast-is-your-cpu.html">How fast is your CPU?</a></span></li>
          
        </ul>        
      </header>
      <section>
        <div class='posts'>
  
    <div>
      <h3><span>01 May 2012</span> &raquo; <a href='/2012/05/01/circuit-breaker-pattern-revisited.html'>Circuit Breaker Pattern Revisited</a></h3>
      <div>
        <p>The circuit breaker pattern can be really useful when building a system based on distributed services. It helps to keep the whole system healthy even when some of its sub-services have troubles. The first proposal of the circuit breaker for this kind on problem I found in Michael Nygard&#8217;s great book, <a href='http://www.pragprog.com/titles/mnee/release-it'>Release It!</a>. The pattern doesn&#8217;t require sophisticated implementation. But you don&#8217;t even have to do it because there are some ready solutions like the Spring-based <a href='http://code.google.com/p/kite-lib/'>kite-lib</a>. Let&#8217;s check what&#8217;s inside.</p>

<p>The core logic of the circuit breaker extracted from the library:</p>

<pre><code>public class CircuitBreakerTemplate {
  public enum State { CLOSED, OPEN, HALF_OPEN };
  private int exceptionThreshold = 5; 
  private long timeout = 30000L;
  private volatile State state = State.CLOSED;
  private final AtomicInteger exceptionCount = new AtomicInteger(); 
  private volatile long attemptResetAfter = Long.MAX_VALUE;

  public State getState() { 
    if (state == State.OPEN) {
      if (System.currentTimeMillis() &gt;= attemptResetAfter) { 
        this.state = State.HALF_OPEN;
      }
    } 
    return state;
  }

  public void reset() {
    this.state = State.CLOSED; 
    this.exceptionCount.set(0);
  }

  public void trip() {
    this.state = State.OPEN; 
    this.attemptResetAfter = System.currentTimeMillis() + timeout;
  }

  public &lt;T&gt; T execute(CircuitBreakerCallback&amp;lt;T&amp;gt; action) throws Exception { 
    final State currState = getState(); 
    switch (currState) {
      case CLOSED:
        try {
          T value = action.doInCircuitBreaker(); 
          this.exceptionCount.set(0); 
          return value;
        } catch (Exception e) {
          if (exceptionCount.incrementAndGet() &gt;= exceptionThreshold) { trip(); } 
          throw e;
        }
      case OPEN: throw new RuntimeException(&quot;CircuitOpenException&quot;);
      case HALF_OPEN:
        try {
          T value = action.doInCircuitBreaker(); 
          reset();
          return value; 
        } catch (Exception e) {
          trip(); 
          throw e;
        }
      default: throw new IllegalStateException(&quot;Unknown state: &quot; + currState);
    }
  }
}

interface CircuitBreakerCallback&amp;lt;T&amp;gt; {
  T doInCircuitBreaker() throws Exception;
}</code></pre>

<p>The code is copied from the library - just simplified a little, without Spring and monitoring (JMX) stuff.</p>

<p>It just forwards requests to the target service as long as the service is up which means the number of allowed failures isn&#8217;t reached. When the configured number of allowed failures is reached the circuit is switched to OPEN state for some defined time (timeout). After the timeout the circuit breaker tries access the service once again and in case of success the state is switched to CLOSED. Otherwise it&#8217;s OPEN again. It&#8217;s really basic logic and implementation useful in 95% of cases. But we are free to think about different scenarios as well. Maybe our service sometimes is really slow for quite long time e.g. a few days. In such case the above implementation will access the service every defined period of time making that overall system response slow. Of course we can tune all the parameters through the JMX but it&#8217;s manual work. Maybe the solution which instead of periodical checking notifies us when the service is fast again would be better?</p>

<h3 id='threads_to_rescue'>Threads to rescue</h3>

<p>Instead of using timeout for implementing scenario when the circuit is OPEN we can use a background thread. The thread can be started when the number of allowed failures is reached (like in previous implementation) to monitor the service. In the meantime the attempts to access the service can be rejected with the original exception (the last handled exception from the service). When the thread decides that the service is healthy again the circuit can be closed.</p>

<pre><code>public class CircuitBreaker implements InvocationHandler {
  private int maxFailures = 3;
  private AtomicInteger failures = new AtomicInteger(0);
  private volatile Throwable lastThrowable;
  private volatile Thread monitor;
  private RemoteServiceClient remoteServiceClient;
  private long timeoutBetweenChecks = 2000;

  public Object invoke(Object proxy, final Method method, final Object[] args) throws Throwable {
    if (lastThrowable != null) {
      throw lastThrowable;
    }
    try {
      return method.invoke(remoteServiceClient, args);
    } catch (Throwable t) {
      if (failures.incrementAndGet() == maxFailures) {
        monitor = new Thread(new Runnable() {
          boolean fails = true;
          public void run() {
            while (fails) {
              lastThrowable = t.getCause();
              try {
                Thread.sleep(timeoutBetweenChecks);
                method.invoke(remoteServiceClient, args);
                failures.set(0);
                lastThrowable = null;
                fails = false;
              } catch (Throwable t) {}
            }
          }
        });
        monitor.start();
      }
      throw t.getCause();
    }
  }
}</code></pre>

<h3 id='safety_vs_performance'>Safety vs Performance</h3>

<p>The environment for the solution is multithreaded by its nature. In most cases it&#8217;s a web application aggregating content from external services. This kind of application has thread pool used to process request handlers. So the circuit breaker needs to be prepared to be executed by many threads at the same time. Also, it must be transparent for the whole system especially in terms of performance and liveness. The biggest risk with the solution (in both implementations) is the situation that the circuit is OPEN even in the case when the service is healthy again. That&#8217;s something we have to prevent for sure. At the same time we can not make too much locking especially for the case when everything is fine.</p>

<p>Both solutions are based on similar pattern - global mutable variable holding the state of the circuit. What we must be sure here is the fact that modifications to this state must be propagated through the CPU caches to main memory so that other threads can see it. Because the change of this variable isn&#8217;t based on the previous value (read-modify-write) we can do it with quite lightweight <code>volatile</code>. We have also additional global variable - failures counter. In this case we couldn&#8217;t use <code>volatile</code> for it because <code>failures++</code> isn&#8217;t atomic (read-modify-write). So, <code>AtomicInteger.incrementAndGet</code> is used which is a little more expensive (from the performance point of view) then <code>volatile</code> but much less then any explicit locking.</p>

<p>It must be said that the second implementation is more risky because of this additional monitor thread which is the only one place where once opened circuit can be closed. So in case the monitor thread dies we must have some fallback solution in place. Also it might happen that the monitor thread failed at startup, so we should have here some logic to reset the failures counter after some time/value.</p>

<h3 id='final_notes'>Final notes</h3>

<ul>
<li>The solution proposed by me isn&#8217;t the standard way of implementing the pattern, so use it only if you really need it. The original one should be sufficient in most cases.</li>

<li>The circuit breaker can be really useful but should not be used to hides problems in your system/architecture. You must be sure that the case when the sub-service is down or slow is really normal case. It shouldn&#8217;t be a workaround for some problems of unstable services.</li>
</ul>
      </div>
    </div>
  
    <div>
      <h3><span>21 Mar 2012</span> &raquo; <a href='/2012/03/21/java-array-memory-allocation.html'>Java array memory allocation</a></h3>
      <div>
        <p>There are two ways to create an array in Java:</p>

<ul>
<li>array creation expression: <code>int[] array = new int[5]</code></li>

<li>array initializer: <code>int[] array = {0,0,0,0,0}</code></li>
</ul>

<p>Both cases require the element type and the array length to be specified. These two values are needed to allocate appropriate memory structure for the array. Arrays in Java are just objects and theirs memory representation is quite similar:</p>
<img src='http://4.bp.blogspot.com/-WeX8Ap6bQVM/T3xLiQrsUmI/AAAAAAAACPk/mvKb3tjOypk/s1600/JavaObjectStructure.png' />
<p>As we can see we have the header which contains 2 elements (more details later) and additional &#8220;size&#8221; element in case of arrays. After the header there are object fields or array elements placed. Anyway, this is still quite generic description. What if we want to get more detailed and real memory layout for our array? Is there a way to get it from the Java level?</p>

<p><strong>32 vs 64 bits</strong></p>

<p>Before trying to access the memory we need to know which platform we&#8217;re going to use. The diagram below presents possible cases:</p>
<img src='http://4.bp.blogspot.com/-yUbT_ye66Fk/T32hcRQL7xI/AAAAAAAACQU/el5taNPiQuY/s1600/JavaArrayMemory32vs64bit.png' />
<p>It&#8217;s important to remember that all Java objects are aligned to an 8 byte granularity. Because of that we have additional paddings in some cases.</p>

<p>Because of it&#8217;s simplicity 32-bit platform was chosen for the following examples.</p>

<p><strong>The Unsafe</strong></p>

<p>Java allocates and releases memory for our objects on it&#8217;s own and hides memory addresses from us behind object references (in fact they are hidden pointers). But at the same time we have backdoor solution called <code>sun.misc.Unsafe</code> which allows to play directly with the memory.</p>

<p>Note: As the class name says it&#8217;s really unsafe way of accessing memory and shouldn&#8217;t be used in any production code.</p>

<p>Because of its private constructor we need a small trick to create an instance:</p>

<pre><code>try {
  Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
  field.setAccessible(true);
  Unsafe unsafe = (Unsafe) field.get(null);
} catch (Exception e) {}</code></pre>

<p>Having the instance we can use the API which is quite rich e.g. we can read and write values at given addresses and even allocate and free real Java objects. For our purpose we need to just read the memory structure representing our array object, from the begin to the end. We don&#8217;t know the address of given object but&#8217;s it&#8217;s not necessary for this case:</p>

<pre><code>try {
  Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
  field.setAccessible(true);
  Unsafe unsafe = (Unsafe) field.get(null);

  int[] array = {1,2,3,4,5,6,7,8,9};
  long numberOfWords = 3 + 9;

  for (long i = 0; i &lt; numberOfWords; i++) {
    int cur = unsafe.getInt(array, i * 4);
    System.out.println(Integer.toBinaryString(cur));
  }
} catch (Exception e) {}</code></pre>

<p>The output:</p>

<pre><code>1
1100000000010000101011010000
1001
1
10
11
100
101
110
111
1000
1001</code></pre>

<p>Each line represents 4-byte value:</p>

<ul>
<li>Line 1: Mark</li>

<li>Line 2: <code>int[]</code> class object pointer</li>

<li>Line 3: the array size</li>

<li>Line 4-12: the array elements</li>
</ul>

<p><strong>Multi-dimensional arrays</strong></p>

<p>Java implements multidimensional arrays as &#8220;arrays of array references&#8221;:</p>
<img src='http://2.bp.blogspot.com/-PDsnOr3i394/T3xL1DKvShI/AAAAAAAACPw/KZqqQp7vG8U/s1600/Java2DimArrayInMemory.png' />
<p>Printing the array:</p>

<pre><code>try {
  Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
  field.setAccessible(true);
  Unsafe unsafe = (Unsafe) field.get(null);

  int[][] array = ...
  long numberOfWords = 6 + 6 * 3;

  for (long i = 0; i &lt; numberOfWords; i++) {
    int cur = unsafe.getInt(array, i * 4);
    System.out.println(Integer.toBinaryString(cur));
  }
} catch (Exception e) {}</code></pre>

<p>gives:</p>

<pre><code>1
1011001011100011100111011000
11
101000100001110111100100000
101000100001110111100111000
101000100001110111101010000
1
1011000000010000101011010000
11
1
10
11
1
1011000000010000101011010000
11
100
101
110
1
1011000000010000101011010000
11
111
1000
1001</code></pre>

<p>We have 4 arrays of the same size 3. The only difference is that the first array contains references/pointers to arrays with concrete int values.</p>
      </div>
    </div>
  
    <div>
      <h3><span>12 Feb 2012</span> &raquo; <a href='/2012/02/12/the-best-abstractions-are-your-own.html'>The best abstractions are your own</a></h3>
      <div>
        <p>
  Let me tell you the story of one particular project from early 00's. It's not a project I was involved in but i was told so many things about it that I feel like I was there. That time frameworks weren't very popular. There were no Spring, Hibernate, GWT, JSF, really nothing except EJB 2.x and plain JSP/Servlets. The team had to implement business application with the requirements similar for CMS. They started implementing it and somehow found out that they need kind of framework. So instead of doing what they ware paid for - implementing requirements - they focused on something which at the end was quite similar to Struts 1.x (released a few months later). After many months of hard work on this brilliant, abstract framework for the application they realized that it's just too late for the product. It was a big failure for the project and whole team.
</p><p>
  What's the lesson? Don't build your own framework? It's much easier to say it now when we have a lot of frameworks. This lesson has been learned already and it's not a problem in these days - a least I haven't seen such case recently. But what I can see quite often is frameworks mis/overuse. Taking the application from the story I can easily think of at leaset 3 frameworks used in some typical implementation. Is it bad? Not necessarily but can be.
</p><h4>Not only frameworks</h4><p>
  Generally abstractions are about hiding details of some complexity behind a interface which is simpler and closer to the problem we have. So that having OO model and the requirement to make it persistent in e.g. MySQL we aren't forced to solve ORM mismatch ourself and we can use some existing library like Hibernate. Abstractions are around us and we use them a lot e.g. TCP/IP for networking, streams for disk data. Why do we use them? Because they speed up our work making it easier and more standardized. Frameworks are just one type of abstractions.
</p><h4>The problem</h4><p>
  So, where is the problem? First of all: <a href='http://www.joelonsoftware.com/articles/LeakyAbstractions.html'><i>All non-trivial abstractions, to some degree, are leaky.</i></a> - Joel Spolsky.
 </p><p>
  In many Java server-side applications we use Hibernate for the ORM problem. This is quite good abstraction but it's also typical for non-experienced team to get performance problems really soon. Why? Mostly because the tool was learned and used as black box only through its specification/api without monitoring what, when and how many quires are generated behind the scene. Spring Framework provides good mechanism for doing declarative transactions but here also knowing only the annotations which should be applied can cause problems with poor performance or even with lost data. It's not only related to frameworks and libs. Scala is getting very popular recently. There are many tutorials and talks showing how nice the operations on collections can be made. But at some time we can be punished by Garbage Collector if we overuse this style (a lot of temporal objects and memory allocations). 
</p><h4>Summary</h4><p>
  We should use abstractions (frameworks, libraries, new languages) but to be really proficient and safe with them we need to know them almost like theirs creators. We should not use them as black boxes denying the details. We should know all side effects if they are. We should look into source code if we have. We should own them. If we are not able to own all abstractions used in our project then we should limit theirs number.
</p>
      </div>
    </div>
  
    <div>
      <h3><span>05 Jan 2012</span> &raquo; <a href='/2012/01/05/how-fast-is-your-cpu.html'>How fast is your CPU?</a></h3>
      <div>
        <p>
  According <a href='http://ark.intel.com/products/47341/Intel-Core-i5-520M-Processor-(3M-Cache-2_40-GHz)' target='_blank'>the specification</a> i5 CPU in my MacBookPro 2010 doesn't seem to be really fast in these days. It wasn't even the top model when i bought the laptop almost 2 years ago. Since that time new series of i5 and i7 have been released. Also, right now we have CPUs based on totally new architecture - <a href='http://software.intel.com/en-us/articles/sandy-bridge/' target='_blank'>Sandy Bridge</a>. But still I'm convinced that the CPU I have is really fast, much faster what i had in past and - what can be surprising - faster then you may think when reading the spec. To prove that i will compare it to some of my old laptops:
</p><ul>
  <li><a href='http://www.everymac.com/systems/apple/macbook_pro/stats/macbook-pro-core-i5-2.4-aluminum-15-mid-2010-unibody-specs.html' target='_blank'>MacBookPro 2010, i5 2.4GHz, 8GB RAM</a></li>
  <li><a href='http://www.sony.co.uk/product/vn-cw-series/vpccw1s1e-r' target='_blank'>Sony VAIO 2009, Core 2 Duo 2.13GHz, 4GB RAM</a></li>
  <li><a href='http://eu.computers.toshiba-europe.com/innovation/jsp/SUPPORTSECTION/discontinuedProductPage.do?service=EU&PRODUCT_ID=97587' target='_blank'>Toshiba Satellite 2004, Pentium M 1.6GHz, 1GB RAM</a></li>
</ul><p>
  From <a href='http://ark.intel.com/compare/36734,27584,47341' target='_blank'>the CPUs comparison</a> we can see that Core 2 Duo and i5 seems to be quite similar but Pentium M looks like something from the previous century. To test them i'm not going to use any available benchmarking tool but i will try to do something on my own. Of course this way won't provide anything sophisticated which would test all possible aspects and gave absolute results ready to publish and compare to others. But that's not my goal. In this post i will try to touch only one aspect of these CPUs - caches and memory access - and leave other stuff like threading for further topics.
</p><h4>Tested on</h4><p>
<table>
  <tbody>
    <tr><td>MacBookPro</td><td>OSX 10.6.8</td><td>64-bit</td><td>OpenJDK build 1.7.0-jdk7u4-b17-20120323</td></tr>
    <tr><td>Sony VAIO</td><td>Windows 7</td><td>64-bit</td><td>build 1.7.0_03-b05</td></tr>
    <tr><td>Toshiba Satellite</td><td>Ubuntu 11.10</td><td>32-bit</td><td>OpenJDK 1.7.0_147-icedtea (from apt repository)</td></tr>
  </tbody>
</table>
</p><h4>The test</h4><pre><code>public class CPUTest {
  private static final int SIZE_X = 4 * 1024;
  private static final int SIZE_Y = 4 * 1024;
  private static final int ITERATIONS = 100;
  private static final int[][] array = new int[SIZE_X][SIZE_Y];

  public static void main(String[] args) throws Exception {
    // warm-up
    for (int x = 0; x &lt; SIZE_X; x++) {
      for (int y = 0; y &lt; SIZE_Y; y++) {
        array[x][y] = 1;
      }
    }

    final long startTime = System.nanoTime();

    for (int r = 0; r &lt; ITERATIONS; r++) {
      for (int x = 0; x &lt; SIZE_X; x++) {
        for (int y = 0; y &lt; SIZE_Y; y++) {
          array[x][y]++;
        }
      }
    }

    final long duration = System.nanoTime() - startTime;
    System.out.println(duration / 1000000 / ITERATIONS);
  }
}</code></pre><p>
  The test just iterates over quite big (64MB) array of ints and increments each of them. To get more accurate results we have one additional iteration at the begin called warm-up and whole measured code block is repeated 100 times.<br />
  My results:
</p><table>
  <tbody>
    <tr><td>1.</td><td>i5</td><td>15</td></tr>
    <tr><td>2.</td><td>Core 2 Duo</td><td>31</td></tr>
    <tr><td>3.</td><td>Pentium M</td><td>135</td></tr>
  </tbody>
</table><p>
  The order itself isn't surprising but the numbers are quite interesting. i5 and Core 2 Duo look quite similar when reading the specifications but the test shows that there is significant improvement introduced in i5 in the way memory access and caches work in this test case. Pentium M is totally out of the competition here - 9 times slower the i5.
</p><p>The next test is "almost" the same - only one change in the above code:</p><pre><code>array[x][y]++</code></pre><p>to</p><pre><code>array[y][x]++</code></pre><p>My results:</p><table>
  <tbody>
    <tr><td>1.</td><td>Core 2 Duo</td><td>254</td></tr>
    <tr><td>2.</td><td>i5</td><td>330</td></tr>
    <tr><td>3.</td><td>Pentium M</td><td>400</td></tr>
  </tbody>
</table><p>
  First of all, current results are much worse then previous. But what's really surprising here is the fact that newer i5 is slower the Core 2 Duo in this test. It's something what wasn't expected by me when doing the tests. To try to explain it somehow we need to get deeper into JVM, memory and CPU.
</p><h3>What does exactly the test do?</h3><ul>
  <li>it defines and allocates memory for 4096x4096 2-dimensional array of ints which gives 64MB</li>
  <li>it iterates over it and reads value from each element which gives over 16 millions of iterations and memory reads</li>
</ul><h4>Java / JVM / Arrays / Memory</h4><p>
  When defining an array in the following way: <code>int[] array = new array[100]</code> we have continuous block of (100 + 3) * 4 bytes allocated in the memory on 32-bit JVM. Multi-dimensional arrays are a little different. Java/JVM implements them as "array of array references". When defining 2-dimensional array it's required to specify size only for the first dimension: <code>int[][] array = new int[100][]</code> which btw will allocate the same number of bytes in the memory like the previous definition. That's because we defined the array for references to int[] class objects which have (on 32-bit JVM) the same size as int - 4 bytes.<br />
  Anyway, in the test the array is defined with concrete sizes for both dimensions which means that memory for all arrays is allocated at once in the following way:
</p><img src='http://3.bp.blogspot.com/-424ytTIpIQc/T3nl597EFoI/AAAAAAAACOE/ZZLJP6RqsIU/s1600/2-dim-arrays.png' border='0' /><p>What's really important here is the fact that all arrays are allocated as continuous memory block.</p><h4>CPU overview</h4><p>Generally CPU can be described as a loop of the following steps:</p><ul>
  <li>fetch a instruction and decode it</li>
  <li>fetch a memory data if needed</li>
  <li>execute instruction</li>
  <li>store the result back to memory</li>
</ul><p>
  Seems to be a lot of work for single pass. Fortunately that's not how the CPUs work these days. First of all most of the steps above are made in parallel even in one single core - modern CPU has even 6+ execution units per core. The second important thing are caches. We have multi-level instruction and data caches which can help a lot if we allow them. When CPU needs some data first it looks in registers then caches L1, L2, L3 and then goes to the memory. Of course each next step in this checking has much higher access time. Because of that when some data is read from the memory will be stored in caches for some possible usage in future. And not only bytes which are needed right now but also many next bytes which are likely to be needed soon. This way in one memory read access CPU can get a lot of data and in case the pre-fetching was accurate it will save a lot of time/cycles. So that's why the first test version is so fast - it just accesses the memory in a linear way allowing caches to do it's best. It's just cache friendly. But the second version which makes a lot of jumps through the memory just fights against CPU and it's caches not only ignoring it's power but also wasting time needed for handling cache misses. Also the things getting even more complicated when considering threading but that's a case for it's own topic.
</p><p>
  <img src='http://2.bp.blogspot.com/-FuIP_W7YF60/T3q4Dt5Dj4I/AAAAAAAACOc/aXQe7qxP2aE/s1600/cpu.png' border='0' /><br />
  CPU cache architecture overview
</p><h4>Summary</h4><p>
  The most important observation from the tests is not the fact that caches help because it's quite obvious but the factor how much. All CPUs perform better when accessing memory in linear way but the numbers differ a lot:
</p><ul>
  <li>Pentium M ~ 3 times</li>
  <li>Core 2 Duo ~ 8 times</li>
  <li>i5 ~ 22 times !!!</li>
</ul><p>
  The newer CPU the difference is bigger which means caches and pre-fetching logic getting more and more important when writing a code these days. Such small (stupid) change like the one in the test can lead to drastically different results.
</p>
      </div>
    </div>
  
</div>
      </section>
      <footer>
        <p><small>Hosted on GitHub Pages</small></p>
      </footer>
    </div>
    <!-- <script src="javascripts/scale.fix.js"></script>
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-31173165-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script> -->

  </body>
</html>